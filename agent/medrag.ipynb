{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "556340b3-1ce2-424f-9aea-5b908854774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U langgraph langsmith langchain-openai langchain_tavily langchain_ollama fastapi[all] websockets tavily-python boto3 langchain_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27d892aa-b822-4384-b6e9-40fb96246989",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid reducer signature. Expected (a, b) -> c. Got (x)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magent_runner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m call_agent\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Step 1: Define the structured input\u001b[39;00m\n\u001b[32m      5\u001b[39m input_data = {\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mchest xray tumor image\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimage_path\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m/path/to/chest_xray.jpg\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/manusinh/medRAG/agent/agent_runner.py:178\u001b[39m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mweb_results\u001b[39m\u001b[33m\"\u001b[39m: result}\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# === Assemble LangGraph ===\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m builder = \u001b[43mStateGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAgentState\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m builder.add_node(\u001b[33m\"\u001b[39m\u001b[33mplan\u001b[39m\u001b[33m\"\u001b[39m, plan_node)\n\u001b[32m    180\u001b[39m builder.add_node(\u001b[33m\"\u001b[39m\u001b[33mmedgemma\u001b[39m\u001b[33m\"\u001b[39m, medgemma_node)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/manusinh/venv/lib/python3.12/site-packages/langgraph/graph/state.py:294\u001b[39m, in \u001b[36mStateGraph.__init__\u001b[39m\u001b[34m(self, state_schema, config_schema, input_schema, output_schema, **kwargs)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28mself\u001b[39m.output_schema = cast(\u001b[38;5;28mtype\u001b[39m[OutputT], output_schema \u001b[38;5;129;01mor\u001b[39;00m state_schema)\n\u001b[32m    292\u001b[39m \u001b[38;5;28mself\u001b[39m.config_schema = config_schema\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_add_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstate_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[38;5;28mself\u001b[39m._add_schema(\u001b[38;5;28mself\u001b[39m.input_schema, allow_managed=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    296\u001b[39m \u001b[38;5;28mself\u001b[39m._add_schema(\u001b[38;5;28mself\u001b[39m.output_schema, allow_managed=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/manusinh/venv/lib/python3.12/site-packages/langgraph/graph/state.py:307\u001b[39m, in \u001b[36mStateGraph._add_schema\u001b[39m\u001b[34m(self, schema, allow_managed)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.schemas:\n\u001b[32m    306\u001b[39m     _warn_invalid_state_schema(schema)\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     channels, managed, type_hints = \u001b[43m_get_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m managed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_managed:\n\u001b[32m    309\u001b[39m         names = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(managed)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/manusinh/venv/lib/python3.12/site-packages/langgraph/graph/state.py:1302\u001b[39m, in \u001b[36m_get_channels\u001b[39m\u001b[34m(schema)\u001b[39m\n\u001b[32m   1294\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m   1295\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33m__root__\u001b[39m\u001b[33m\"\u001b[39m: _get_channel(\u001b[33m\"\u001b[39m\u001b[33m__root__\u001b[39m\u001b[33m\"\u001b[39m, schema, allow_managed=\u001b[38;5;28;01mFalse\u001b[39;00m)},\n\u001b[32m   1296\u001b[39m         {},\n\u001b[32m   1297\u001b[39m         {},\n\u001b[32m   1298\u001b[39m     )\n\u001b[32m   1300\u001b[39m type_hints = get_type_hints(schema, include_extras=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1301\u001b[39m all_keys = {\n\u001b[32m-> \u001b[39m\u001b[32m1302\u001b[39m     name: \u001b[43m_get_channel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1303\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, typ \u001b[38;5;129;01min\u001b[39;00m type_hints.items()\n\u001b[32m   1304\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name != \u001b[33m\"\u001b[39m\u001b[33m__slots__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1305\u001b[39m }\n\u001b[32m   1306\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m   1307\u001b[39m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m all_keys.items() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, BaseChannel)},\n\u001b[32m   1308\u001b[39m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m all_keys.items() \u001b[38;5;28;01mif\u001b[39;00m is_managed_value(v)},\n\u001b[32m   1309\u001b[39m     type_hints,\n\u001b[32m   1310\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/manusinh/venv/lib/python3.12/site-packages/langgraph/graph/state.py:1336\u001b[39m, in \u001b[36m_get_channel\u001b[39m\u001b[34m(name, annotation, allow_managed)\u001b[39m\n\u001b[32m   1334\u001b[39m     channel.key = name\n\u001b[32m   1335\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m channel\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m channel := \u001b[43m_is_field_binop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1337\u001b[39m     channel.key = name\n\u001b[32m   1338\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m channel\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/manusinh/venv/lib/python3.12/site-packages/langgraph/graph/state.py:1370\u001b[39m, in \u001b[36m_is_field_binop\u001b[39m\u001b[34m(typ)\u001b[39m\n\u001b[32m   1368\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m BinaryOperatorAggregate(typ, meta[-\u001b[32m1\u001b[39m])\n\u001b[32m   1369\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1370\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1371\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid reducer signature. Expected (a, b) -> c. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msig\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1372\u001b[39m             )\n\u001b[32m   1373\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Invalid reducer signature. Expected (a, b) -> c. Got (x)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from agent_runner import call_agent\n",
    "\n",
    "# Step 1: Define the structured input\n",
    "input_data = {\n",
    "    \"query\": \"chest xray tumor image\",\n",
    "    \"image\": True,\n",
    "    \"image_path\": \"/path/to/chest_xray.jpg\"\n",
    "}\n",
    "# Step 2: Extract fields\n",
    "query = input_data.get(\"query\", \"\")\n",
    "image_flag = input_data.get(\"image\", False)\n",
    "image_path = input_data.get(\"image_path\", \"\")\n",
    "\n",
    "# Step 3: Format into a single string\n",
    "final_input_str = f\"Query: {query}\\nImage: {image_flag}\\nImage Path: {image_path}\"\n",
    "\n",
    "# Step 4: Send to agent\n",
    "data = []\n",
    "skip = False\n",
    "tool_use = False\n",
    "for step in call_agent(final_input_str):\n",
    "    print(step)\n",
    "#     if len(data):\n",
    "#         for old_step in data:\n",
    "#             if step[\"type\"]==old_step[\"type\"] and step[\"data\"]==old_step[\"data\"]:\n",
    "#                 skip = True\n",
    "#                 break\n",
    "#             else:\n",
    "#                 skip = False  \n",
    "#     if not skip and step[\"type\"]==\"tool\":\n",
    "#         tool_use = True\n",
    "#         print(step)\n",
    "#     data.append(step)\n",
    "\n",
    "# if not tool_use: \n",
    "#     for step in data:\n",
    "#         if step[\"type\"]==\"ai\":\n",
    "#             tool_use = False\n",
    "#             print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97ae7daf-4e4b-40c4-8464-a19a7727dc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'ai', 'data': 'type: ai\\ndata: This assistant is designed strictly for medical image processing and search. Please ask a medical-related question.\\nnext_tool: no_tool'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from agent_runner import call_agent\n",
    "\n",
    "# Step 1: Define the structured input\n",
    "input_data = {\n",
    "    \"query\": \"Hi\",\n",
    "    \"image\": False,\n",
    "    \"image_path\": \"\"\n",
    "}\n",
    "# Step 2: Extract fields\n",
    "query = input_data.get(\"query\", \"\")\n",
    "image_flag = input_data.get(\"image\", False)\n",
    "image_path = input_data.get(\"image_path\", \"\")\n",
    "\n",
    "# Step 3: Format into a single string\n",
    "final_input_str = f\"Query: {query}\\nImage: {image_flag}\\nImage Path: {image_path}\"\n",
    "\n",
    "# Step 4: Send to agent\n",
    "data = []\n",
    "skip = False\n",
    "tool_use = False\n",
    "for step in call_agent(final_input_str):\n",
    "    if len(data):\n",
    "        for old_step in data:\n",
    "            if step[\"type\"]==old_step[\"type\"] and step[\"data\"]==old_step[\"data\"]:\n",
    "                skip = True\n",
    "                break\n",
    "            else:\n",
    "                skip = False  \n",
    "    if not skip and step[\"type\"]==\"tool\":\n",
    "        tool_use = True\n",
    "        print(step)\n",
    "    data.append(step)\n",
    "\n",
    "if not tool_use: \n",
    "    for step in data:\n",
    "        if step[\"type\"]==\"ai\":\n",
    "            tool_use = False\n",
    "            print(step)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f275f63-4bdd-44e9-8ab4-9a847cd53acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 cp s3://medgemma/unique_subset ./unique_subset --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a35df08-ab15-4af9-9dd1-0c444ddef196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (0.5.1)\n",
      "Requirement already satisfied: langchain-core>=0.1 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from langgraph) (0.3.68)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from langgraph) (2.1.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.6.0,>=0.5.0 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from langgraph) (0.5.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from langgraph) (0.1.72)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from langgraph) (2.11.7)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.18)\n",
      "Requirement already satisfied: anyio in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.16.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (0.4.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ubuntu/manusinh/venv/lib/python3.12/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38929526-2ea9-4441-882f-28ac3ec819a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
